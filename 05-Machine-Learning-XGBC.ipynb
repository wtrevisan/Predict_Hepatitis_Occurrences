{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# `Project:` Prevendo a <font color='blue'>morte</font> ou <font color='blue'>vida</font> de pacientes com hepatite\n",
    "\n",
    "## `Date:` fevereiro, 2022\n",
    "\n",
    "## `Data Scientist:` Walter Trevisan\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='notebook-header'></a>\n",
    "## `Modelagem Preditiva` (*`Machine Learning`*) - [XGBoost Classifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html?highlight=xgbclassifier#xgboost.XGBClassifier)\n",
    "\n",
    "Neste **notebook** vamos realizar a **modelagem preditiva** treinando e analisando alguns modelos preditivos criados com o algoritmo **XGBoost Classifier**. Para fazermos o treinamento dos modelos utilizaremos os *data sets* de treino e para avaliarmos a performance dos modelos utilizaremos o *data set* de teste que foram criados e preparados na etapa anterior (`Data Munging`).\n",
    "\n",
    "### Conteúdo\n",
    "1. [Setup Inicial](#initial-setup)\n",
    "\n",
    "2. [Carregar os *dataframes* de treino e de teste](#load-data)\n",
    "\n",
    "3. [Treinar e Avaliar os modelos preditivos](#modelos-treinar-avaliar)\n",
    "\n",
    "4. [Concluir e salvar o **melhor modelo preditivo** construído com o **XGBoost Classifier**](#modelos-conclusao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='initial-setup'></a>\n",
    "## <font color='blue'>1- Setup Inicial:</font>\n",
    "\n",
    "Primeiro, vamos carregar os **pacotes e funções** que serão utilizadas neste **notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "# As novas versões do Pandas e Matplotlib trazem diversas mensagens de aviso ao desenvolvedor.\n",
    "# Então, vamos desativar essas mensagens.\n",
    "import sys # O pacote \"sys\" permite manipulações com o sistema operacional:\n",
    "import os  # Operation System (Packages and Functions)\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Importa função para verificarmos a versão da linguagem python:\n",
    "from platform import python_version\n",
    "\n",
    "# Importando os pacote NumPy:\n",
    "import numpy as np\n",
    "# Importando os pacote Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "# Importando pacotes para visualização de gráficos:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# Importa o pacote \"seaborn\" para criarmos gráficos estatísticos:\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning imports\n",
    "# Importando o pacote do Scikit-Learn:\n",
    "import sklearn as skl\n",
    "# Função para padronização de variáveis:\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "# Importando algoritmo de classificação:\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Definindo uma \"semente\" para reproduzir os mesmos dados nas tarefas de amostragem,\n",
    "# balanceamento dos dados e treinamento dos modelos preditivos:\n",
    "SEED = 42\n",
    "\n",
    "# Nota: Como vamos equilibrar nossos dados de treinamento, através do \"balanceamento\" de classes,\n",
    "# vamos definir nosso limite (threshold) em \"0.5\" para rotular uma amostra prevista como positiva.\n",
    "# Portanto, as probabilidades previstas acima deste valor (THRESHOLD) serão rotuladas como positiva\n",
    "# (target=1), ou seja, significa que os pacientes com hepatite sobreviveram (LIVE).\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# Define valor para \"Cross Validation\" (Número de 'folds'):\n",
    "NUM_FOLDS=10 # Número de passadas (\"folds\")\n",
    "\n",
    "# Definindo o diretório raiz (Root) onde serão armazenados todas as informações\n",
    "# (Imagens, Gráficos, Objetos, Dados, Modelos de ML, etc...) do projeto.\n",
    "# Diretório Raiz (Root) do Projeto:\n",
    "ROOT_DIR = \".\"\n",
    "\n",
    "# Path: onde ficarão armazenados os \"Objetos\" (Estrututras de Dados) relacionados ao Projeto:\n",
    "OBJ_PATH = os.path.join(ROOT_DIR, \"objects\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(OBJ_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde ficarão armazenados os \"datasets\" (arquivos \"csv\") e os \"objetos\" (Data Frames) do Projeto:\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde serão armazenadas as \"Imagens\" (Figuras e Gráficos) do Projeto:\n",
    "GRAPHICS_PATH = os.path.join(ROOT_DIR, \"images\", \"graphics\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(GRAPHICS_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde ficarão armazenados os \"Modelos Preditivos\" (Machine Learning) relacionados ao Projeto:\n",
    "ML_PATH = os.path.join(ROOT_DIR, \"models\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(ML_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde estão armazenadas as classes e funções que serão utilizadas neste notebook:\n",
    "LIB_PATH = os.path.join(ROOT_DIR, \"library\")\n",
    "\n",
    "# Adicionando o diretório \"./library\" ao 'path' do Sistema, para podermos importar classes e funções que serão\n",
    "# utilizadas neste notebook:\n",
    "sys.path.append(LIB_PATH)\n",
    "\n",
    "# Importando para este notebook, as classes e funções definidas no módulo \"data_science_library.py\":\n",
    "import data_science_library as dslib\n",
    "\n",
    "# Importando para este notebook, as classes e funções definidas no módulo \"plot_library.py\":\n",
    "import plot_library as ptlib\n",
    "\n",
    "# Importando para este notebook, as classes e funções definidas no módulo \"machine_learning_library.py\":\n",
    "import machine_learning_library as mllib\n",
    "\n",
    "# Criando um objeto para calularmos os tempos gastos de treinamento:\n",
    "ept = dslib.ElapsedTime(builder_msg=False)\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versões dos pacotes usados neste jupyter notebook:\n",
      "Python      : 3.8.12\n",
      "Numpy       : 1.19.5\n",
      "Pandas      : 1.3.5\n",
      "Matplotlib  : 3.4.3\n",
      "Seaborn     : 0.11.2\n",
      "Scikit-Learn: 1.0.2\n",
      "XGBoost     : 1.4.2\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook:\n",
    "print(\"Versões dos pacotes usados neste jupyter notebook:\")\n",
    "print(\"Python      : {}\".format(python_version()))\n",
    "print(\"Numpy       : {}\".format(np.__version__))\n",
    "print(\"Pandas      : {}\".format(pd.__version__))\n",
    "print(\"Matplotlib  : {}\".format(mpl.__version__))\n",
    "print(\"Seaborn     : {}\".format(sns.__version__))\n",
    "print(\"Scikit-Learn: {}\".format(skl.__version__))\n",
    "print(\"XGBoost     : {}\".format(xgb.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='load-data'></a>\n",
    "## <font color='blue'>1- Carregar os *data frames* de `treino` e `teste`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treino:\n",
    "\n",
    "* `train_set_v1`: nesta versão apenas apliquei **encoding** nas variáveis categóricas;\n",
    "\n",
    "* `train_set_v2`: nesta versão também apliquei **encoding** nas variáveis categóricas; e tratei e **removi os outliers** existentes nas variáveis numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto para armazenar as versões dos dataframes de treino:\n",
    "train_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataframe de treino \"train_set_v1\":\n",
    "train_set['v1'] = dslib.pickle_object_load(path=DATA_PATH, file=\"train_set_v1.pkl\")\n",
    "# Carregando o dataframe de treino \"train_set_v2\":\n",
    "train_set['v2'] = dslib.pickle_object_load(path=DATA_PATH, file=\"train_set_v2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Teste:\n",
    "\n",
    "* `test_set`: tratei os valores ausentes nas variáveis categóricas e numéricas; apliquei **encoding** nas variáveis categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataframe de teste \"test_set\":\n",
    "test_set = dslib.pickle_object_load(path=DATA_PATH, file=\"test_set.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='modelos-treinar-avaliar'></a>\n",
    "## <font color='blue'>3- Treinar e Avaliar os modelos preditivos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma instância do algoritmo `XGBoost Classifier` com os hiperparâmetros padrão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma instância do classificador que será treinado a avaliado em cada versão:\n",
    "clf = XGBClassifier(eval_metric=roc_auc_score, random_state=SEED)\n",
    "# Label do modelo:\n",
    "model_label = 'XGBC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dicionário para armazenar os `modelos` treinados e avaliados em cada `versão`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário (objeto) para armazenar os \"modelos\" preditivos treinados e avaliados de cada versão:\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as variáveis preditoras `categóricas`, `numéricas` e a variável `target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a variável \"target\" (Class):\n",
    "target_variable = 'Class'\n",
    "# Definindo as variáveis categóricas preditoras:\n",
    "cat_variables = ['Gender', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'LiverBig', 'LiverFirm',\n",
    "                 'SpleenPalpable', 'Spiders', 'Ascites', 'Varices', 'Histology']\n",
    "# Definindo as variáveis numéricas preditoras:\n",
    "num_variables = ['Age', 'Bilirubin', 'AlkPhosphate', 'SGOT', 'Albumin', 'Protime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dicionário para armazenar as `features` que serão utilizadas em cada versão: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis preditoras:\n",
    "features = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dicionário para armazerarmos o `scaler` aplicado aos dados de `treino`e `teste` em cada versão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler:\n",
    "scaler = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo um *dataframe* para armazenar as métricas de `treino` e `teste`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas nos dados de treino:\n",
    "train_mtcs = {}\n",
    "# Métricas nos dados de teste:\n",
    "test_mtcs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Version, Model, Data set, AUC, Accuracy, Precision, Recall, F1_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando o dataframe para armazenar as métricas de cada versão:\n",
    "metrics = pd.DataFrame(columns=['Version', 'Model', 'Data set', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataframe para armazenar as métricas da melhor versão de cada algoritmo:\n",
    "models_best_metrics = dslib.pickle_object_load(path=ML_PATH, file=\"models_best_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as `versões` dos modelo preditivos que serão treinados e avaliados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um dicionário dos modelos que serão criados com os parâmetros de cada versão:\n",
    "models_version = {\n",
    "    'v01':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':False,'random_state':None},\n",
    "    'v02':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':False,'random_state':None},\n",
    "    'v03':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':False,'random_state':None},\n",
    "    'v04':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':False,'random_state':None},\n",
    "    'v05':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':True,'random_state':SEED},\n",
    "    'v06':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':True,'random_state':SEED},\n",
    "    'v07':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':True,'random_state':SEED},\n",
    "    'v08':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':True,'random_state':SEED},\n",
    "    'v09':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':False,'random_state':None},\n",
    "    'v10':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':False,'random_state':None},\n",
    "    'v11':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':False,'random_state':None},\n",
    "    'v12':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':False,'random_state':None},\n",
    "    'v13':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':True,'random_state':SEED},\n",
    "    'v14':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':True,'random_state':SEED},\n",
    "    'v15':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':True,'random_state':SEED},\n",
    "    'v16':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':True,'random_state':SEED},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a avaliando cada `versão` do modelo preditivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento e avaliação de cada versão do modelo...\n",
      "[11:41:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:41:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Tempo gasto: 1 second.\n",
      "\n",
      "We trained and evaluated 16 predictive models!\n"
     ]
    }
   ],
   "source": [
    "# Inicia o treinamento e avaliação de cada modelo:\n",
    "ept.start(msg=\"Iniciando o treinamento e avaliação de cada versão do modelo...\")\n",
    "# Loop para treinar e avaliar cada versão do modelo:\n",
    "for v, p in models_version.items():\n",
    "    # Preparando os dados de \"treino\" (X_train e y_train) e \"teste\" (X_test e y_test):\n",
    "    X_train, y_train, X_test, y_test, scaler[v] = mllib.prepare_train_test_data(\n",
    "    train_set=train_set[p['train_set']], test_set=test_set, target=target_variable, cat_features=p['cat_variables'],\n",
    "    num_features=p['num_variables'], scaler=p['scaler'], balance=p['balance'], random_state=p['random_state'], verbose=False\n",
    "    )\n",
    "    # Treinando e avaliando a versão do modelo preditivo:\n",
    "    models[v], train_mtcs, test_mtcs = mllib.train_validate_binary_clf_model(\n",
    "        classifier=clf, X_train=X_train, y_train=y_train, X_valid=X_test, y_valid=y_test, \n",
    "        probability=True, threshold=THRESHOLD, verbose=False\n",
    "    )\n",
    "    # Salvando as variáveis preditoras:\n",
    "    features[v] = p['cat_variables']+p['num_variables']\n",
    "    # Salvando as métricas dos dados de treino:\n",
    "    metrics = metrics.append(\n",
    "        pd.DataFrame(\n",
    "            data=[{'Version':v, 'Model':model_label,'Data set':'train','AUC':train_mtcs['auc'],'Accuracy':train_mtcs['accuracy'],\n",
    "                   'Precision':train_mtcs['precision'],'Recall':train_mtcs['recall'],'F1_score':train_mtcs['f1_score']}]\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    # Salvando as métricas dos dados de teste:\n",
    "    metrics = metrics.append(\n",
    "        pd.DataFrame(\n",
    "            data=[{'Version':v,'Model':model_label,'Data set':'test','AUC':test_mtcs['auc'],'Accuracy':test_mtcs['accuracy'],\n",
    "                   'Precision':test_mtcs['precision'],'Recall':test_mtcs['recall'],'F1_score':test_mtcs['f1_score']}]\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# Fim do treinamento e avaliação:\n",
    "ept.end(msg=\"Tempo gasto:\")\n",
    "print(\"\\nWe trained and evaluated {} predictive models!\".format(len(models_version)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise das métricas nos dados de `teste`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v06</td>\n",
       "      <td>XGBC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v08</td>\n",
       "      <td>XGBC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Version Model Data set  AUC  Accuracy  Precision  Recall  F1_score\n",
       "0     v06  XGBC     test  0.9    0.8710     0.9200    0.92     0.920\n",
       "1     v08  XGBC     test  0.9    0.8387     0.9167    0.88     0.898"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os modelos com \"AUC >= 90%\":\n",
    "metrics.query(\"`Data set`=='test' and AUC>=0.9\").sort_values(by='AUC', ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v06</td>\n",
       "      <td>XGBC</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v06</td>\n",
       "      <td>XGBC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Version Model Data set  AUC  Accuracy  Precision  Recall  F1_score\n",
       "0     v06  XGBC    train  1.0     1.000       1.00    1.00      1.00\n",
       "1     v06  XGBC     test  0.9     0.871       0.92    0.92      0.92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando as métricas de treino e teste da versão \"v06\":\n",
    "metrics.query(\"Version=='v06'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise:** considerando os resultados nos dados de teste, as versões **`v06`** e **`v08`** apresentaram o mesmo desempenho na métrica `AUC`, mas a versão **`v06`** foi melhor nas demais métricas. Entretanto, observando as métricas nos dados de treino verificamos que esta versão está com **overfitting** (sobreajuste), ou seja, ela aprendeu muitos detalhes dos dados, incluindo os ruídos. Por este motivo que a sua performance nos dados de teste ficou bem abaixo dos valores obtidos nos dados de treino.\n",
    "\n",
    "Para resolvermos este problema, precisamos obter uma quantidade bem maior de observações (no mínimo 500). Como isto não é possível, concluímos o nosso trabalho com o **XGBoost Classifier**.\n",
    "\n",
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='modelos-conclusao'></a>\n",
    "## <font color='blue'>4- Concluir e salvar o `melhor modelo preditivo` construído com o *XGBoost Classifier*</font>\n",
    "\n",
    "Portanto, o modelo preditivo construido na versão **`v06`** obteve o melhor desempenho na métrica **`AUC`** e também nas outras métricas e por isso, ele foi escolhido como o **melhor modelo preditivo construído com o `XGBoost Classifier`**.\n",
    "\n",
    "Este modelo foi contruido com as seguintes premissas:\n",
    "* utilizamos a `versão 1` dos dados de treino, ou seja, **sem o tratamento de outliers univariados**;\n",
    "\n",
    "* utilizamos **todas** as variáveis preditoras;\n",
    "\n",
    "* fizemos a padronização de escala nas variáveis numéricas utilizando o `StandardScaler`;\n",
    "\n",
    "* **SIM**, fizemos o **balanceamento** do *dataset* de treino, ou seja, criamos registros sintéticos da classe minoritária (`target = 0`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando *todas* as informações do melhor modelo de classificação com `XGBoost Classifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor versão do modelo preditivo:\n",
    "best_version = 'v06'\n",
    "# Cria dataframes para salvar as melhores métricas de treino e teste:\n",
    "best_train_mtcs = metrics.query(\"Version==@best_version and `Data set`=='train'\").reset_index(drop=True)\n",
    "best_test_mtcs = metrics.query(\"Version==@best_version and `Data set`=='test'\").reset_index(drop=True)\n",
    "# Remove a coluna 'Version':\n",
    "best_train_mtcs.drop(columns='Version', inplace=True)\n",
    "best_test_mtcs.drop(columns='Version', inplace=True)\n",
    "# Salva as melhores métricas criadas com este algoritmo:\n",
    "models_best_metrics = models_best_metrics.append(best_train_mtcs, ignore_index=True)\n",
    "models_best_metrics = models_best_metrics.append(best_test_mtcs, ignore_index=True)\n",
    "# Salva as variáveis preditoras, scaler e modelo da melhor versão:\n",
    "best_model = {\n",
    "    'variables': features[best_version],\n",
    "    'scaler': scaler[best_version],\n",
    "    'model': models[best_version]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as métricas dos melhores modelos preditivos:\n",
    "dslib.pickle_object_save (\n",
    "    path=ML_PATH, file=\"models_best_metrics.pkl\", object_name=models_best_metrics, msg=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as informações do melhor modelo preditivo criado com o \"XGBoost Classifier\":\n",
    "dslib.pickle_object_save (\n",
    "    path=ML_PATH, file=\"xgbc_best_model.pkl\", object_name=best_model, msg=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>FIM</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
