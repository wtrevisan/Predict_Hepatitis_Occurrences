{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# `Project:` Prevendo a <font color='blue'>morte</font> ou <font color='blue'>vida</font> de pacientes com hepatite\n",
    "\n",
    "## `Date:` fevereiro, 2022\n",
    "\n",
    "## `Data Scientist:` Walter Trevisan\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='notebook-header'></a>\n",
    "## `Modelagem Preditiva` (*`Machine Learning`*) - [Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "Neste **notebook** vamos realizar a **modelagem preditiva** treinando e analisando alguns modelos preditivos criados com o algoritmo **Decision Tree Classifier**. Para fazermos o treinamento dos modelos utilizaremos os *data sets* de treino e para avaliarmos a performance dos modelos utilizaremos o *data set* de teste que foram criados e preparados na etapa anterior (`Data Munging`).\n",
    "\n",
    "### Conteúdo\n",
    "1. [Setup Inicial](#initial-setup)\n",
    "\n",
    "2. [Carregar os *dataframes* de treino e de teste](#load-data)\n",
    "\n",
    "3. [Treinar e Avaliar os modelos preditivos](#modelos-treinar-avaliar)\n",
    "\n",
    "4. [Trabalhando com **seleção de variáveis** nos melhores modelos preditivos](#modelos-selecao-variaveis)\n",
    "\n",
    "5. [Concluir e salvar o **melhor modelo preditivo** construído com a **Decision Tree Classifier**](#modelos-conclusao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='initial-setup'></a>\n",
    "## <font color='blue'>1- Setup Inicial:</font>\n",
    "\n",
    "Primeiro, vamos carregar os **pacotes e funções** que serão utilizadas neste **notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "# As novas versões do Pandas e Matplotlib trazem diversas mensagens de aviso ao desenvolvedor.\n",
    "# Então, vamos desativar essas mensagens.\n",
    "import sys # O pacote \"sys\" permite manipulações com o sistema operacional:\n",
    "import os  # Operation System (Packages and Functions)\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Importa função para verificarmos a versão da linguagem python:\n",
    "from platform import python_version\n",
    "\n",
    "# Importando os pacote NumPy:\n",
    "import numpy as np\n",
    "# Importando os pacote Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "# Importando pacotes para visualização de gráficos:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# Importa o pacote \"seaborn\" para criarmos gráficos estatísticos:\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning imports\n",
    "# Importando o pacote do Scikit-Learn:\n",
    "import sklearn as skl\n",
    "# Função para padronização de variáveis:\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "# Importando algoritmos de classificação:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo uma \"semente\" para reproduzir os mesmos dados nas tarefas de amostragem,\n",
    "# balanceamento dos dados e treinamento dos modelos preditivos:\n",
    "SEED = 42\n",
    "\n",
    "# Nota: Como vamos equilibrar nossos dados de treinamento, através do \"balanceamento\" de classes,\n",
    "# vamos definir nosso limite (threshold) em \"0.5\" para rotular uma amostra prevista como positiva.\n",
    "# Portanto, as probabilidades previstas acima deste valor (THRESHOLD) serão rotuladas como positiva\n",
    "# (target=1), ou seja, significa que os pacientes com hepatite sobreviveram (LIVE).\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# Define valor para \"Cross Validation\" (Número de 'folds'):\n",
    "NUM_FOLDS=10 # Número de passadas (\"folds\")\n",
    "\n",
    "# Definindo o diretório raiz (Root) onde serão armazenados todas as informações\n",
    "# (Imagens, Gráficos, Objetos, Dados, Modelos de ML, etc...) do projeto.\n",
    "# Diretório Raiz (Root) do Projeto:\n",
    "ROOT_DIR = \".\"\n",
    "\n",
    "# Path: onde ficarão armazenados os \"Objetos\" (Estrututras de Dados) relacionados ao Projeto:\n",
    "OBJ_PATH = os.path.join(ROOT_DIR, \"objects\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(OBJ_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde ficarão armazenados os \"datasets\" (arquivos \"csv\") e os \"objetos\" (Data Frames) do Projeto:\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde serão armazenadas as \"Imagens\" (Figuras e Gráficos) do Projeto:\n",
    "GRAPHICS_PATH = os.path.join(ROOT_DIR, \"images\", \"graphics\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(GRAPHICS_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde ficarão armazenados os \"Modelos Preditivos\" (Machine Learning) relacionados ao Projeto:\n",
    "ML_PATH = os.path.join(ROOT_DIR, \"models\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(ML_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde estão armazenadas as classes e funções que serão utilizadas neste notebook:\n",
    "LIB_PATH = os.path.join(ROOT_DIR, \"library\")\n",
    "\n",
    "# Adicionando o diretório \"./library\" ao 'path' do Sistema, para podermos importar classes e funções que serão\n",
    "# utilizadas neste notebook:\n",
    "sys.path.append(LIB_PATH)\n",
    "\n",
    "# Importando para este notebook, as classes e funções definidas no módulo \"data_science_library.py\":\n",
    "import data_science_library as dslib\n",
    "\n",
    "# Importando para este notebook, as classes e funções definidas no módulo \"plot_library.py\":\n",
    "import plot_library as ptlib\n",
    "\n",
    "# Importando para este notebook, as classes e funções definidas no módulo \"machine_learning_library.py\":\n",
    "import machine_learning_library as mllib\n",
    "\n",
    "# Criando um objeto para calularmos os tempos gastos de treinamento:\n",
    "ept = dslib.ElapsedTime(builder_msg=False)\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versões dos pacotes usados neste jupyter notebook:\n",
      "Python      : 3.8.12\n",
      "Numpy       : 1.19.5\n",
      "Pandas      : 1.3.5\n",
      "Matplotlib  : 3.4.3\n",
      "Seaborn     : 0.11.2\n",
      "Scikit-Learn: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook:\n",
    "print(\"Versões dos pacotes usados neste jupyter notebook:\")\n",
    "print(\"Python      : {}\".format(python_version()))\n",
    "print(\"Numpy       : {}\".format(np.__version__))\n",
    "print(\"Pandas      : {}\".format(pd.__version__))\n",
    "print(\"Matplotlib  : {}\".format(mpl.__version__))\n",
    "print(\"Seaborn     : {}\".format(sns.__version__))\n",
    "print(\"Scikit-Learn: {}\".format(skl.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='load-data'></a>\n",
    "## <font color='blue'>2- Carregar os *data frames* de `treino` e `teste`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treino:\n",
    "\n",
    "* `train_set_v1`: nesta versão apenas apliquei **encoding** nas variáveis categóricas;\n",
    "\n",
    "* `train_set_v2`: nesta versão também apliquei **encoding** nas variáveis categóricas; e tratei e **removi os outliers** existentes nas variáveis numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto para armazenar as versões dos dataframes de treino:\n",
    "train_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataframe de treino \"train_set_v1\":\n",
    "train_set['v1'] = dslib.pickle_object_load(path=DATA_PATH, file=\"train_set_v1.pkl\")\n",
    "# Carregando o dataframe de treino \"train_set_v2\":\n",
    "train_set['v2'] = dslib.pickle_object_load(path=DATA_PATH, file=\"train_set_v2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Teste:\n",
    "\n",
    "* `test_set`: tratei os valores ausentes nas variáveis categóricas e numéricas; apliquei **encoding** nas variáveis categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataframe de teste \"test_set\":\n",
    "test_set = dslib.pickle_object_load(path=DATA_PATH, file=\"test_set.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='modelos-treinar-avaliar'></a>\n",
    "## <font color='blue'>3- Treinar e Avaliar os modelos preditivos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma instância do algoritmo `DecisionTreeClassifier` com os hiperparâmetros padrão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma instância do classificador que será treinado a avaliado em cada versão:\n",
    "clf = DecisionTreeClassifier(random_state=SEED)\n",
    "# Label do modelo:\n",
    "model_label = 'DTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dicionário para armazenar os `modelos` treinados e avaliados em cada `versão`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário (objeto) para armazenar os \"modelos\" preditivos treinados e avaliados de cada versão:\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as variáveis preditoras `categóricas`, `numéricas` e a variável `target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a variável \"target\" (Class):\n",
    "target_variable = 'Class'\n",
    "# Definindo as variáveis categóricas preditoras:\n",
    "cat_variables = ['Gender', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'LiverBig', 'LiverFirm',\n",
    "                 'SpleenPalpable', 'Spiders', 'Ascites', 'Varices', 'Histology']\n",
    "# Definindo as variáveis numéricas preditoras:\n",
    "num_variables = ['Age', 'Bilirubin', 'AlkPhosphate', 'SGOT', 'Albumin', 'Protime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dicionário para armazenar as `features` que serão utilizadas em cada versão: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis preditoras:\n",
    "features = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dicionário para armazerarmos o `scaler` aplicado aos dados de `treino`e `teste` em cada versão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler:\n",
    "scaler = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo um *dataframe* para armazenar as métricas de `treino` e `teste`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas nos dados de treino:\n",
    "train_mtcs = {}\n",
    "# Métricas nos dados de teste:\n",
    "test_mtcs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Version, Model, Data set, AUC, Accuracy, Precision, Recall, F1_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando o dataframe para armazenar as métricas de cada versão:\n",
    "metrics = pd.DataFrame(columns=['Version', 'Model', 'Data set', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataframe para armazenar as métricas da melhor versão de cada algoritmo:\n",
    "models_best_metrics = dslib.pickle_object_load(path=ML_PATH, file=\"models_best_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as `versões` dos modelo preditivos que serão treinados e avaliados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um dicionário dos modelos que serão criados com os parâmetros de cada versão:\n",
    "models_version = {\n",
    "    'v01':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':False,'random_state':None},\n",
    "    'v02':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':False,'random_state':None},\n",
    "    'v03':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':False,'random_state':None},\n",
    "    'v04':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':False,'random_state':None},\n",
    "    'v05':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':True,'random_state':SEED},\n",
    "    'v06':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':True,'random_state':SEED},\n",
    "    'v07':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':True,'random_state':SEED},\n",
    "    'v08':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':True,'random_state':SEED},\n",
    "    'v09':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':False,'random_state':None},\n",
    "    'v10':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':False,'random_state':None},\n",
    "    'v11':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':False,'random_state':None},\n",
    "    'v12':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':False,'random_state':None},\n",
    "    'v13':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':None,'balance':True,'random_state':SEED},\n",
    "    'v14':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':StandardScaler(),'balance':True,'random_state':SEED},\n",
    "    'v15':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':MinMaxScaler(),'balance':True,'random_state':SEED},\n",
    "    'v16':{'train_set':'v2','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':True,'random_state':SEED},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a avaliando cada `versão` do modelo preditivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento e avaliação de cada versão do modelo...\n",
      "Tempo gasto: 0.33 seconds.\n",
      "\n",
      "We trained and evaluated 16 predictive models!\n"
     ]
    }
   ],
   "source": [
    "# Inicia o treinamento e avaliação de cada modelo:\n",
    "ept.start(msg=\"Iniciando o treinamento e avaliação de cada versão do modelo...\")\n",
    "# Loop para treinar e avaliar cada versão do modelo:\n",
    "for v, p in models_version.items():\n",
    "    # Preparando os dados de \"treino\" (X_train e y_train) e \"teste\" (X_test e y_test):\n",
    "    X_train, y_train, X_test, y_test, scaler[v] = mllib.prepare_train_test_data(\n",
    "    train_set=train_set[p['train_set']], test_set=test_set, target=target_variable, cat_features=p['cat_variables'],\n",
    "    num_features=p['num_variables'], scaler=p['scaler'], balance=p['balance'], random_state=p['random_state'], verbose=False\n",
    "    )\n",
    "    # Treinando e avaliando a versão do modelo preditivo:\n",
    "    models[v], train_mtcs, test_mtcs = mllib.train_validate_binary_clf_model(\n",
    "        classifier=clf, X_train=X_train, y_train=y_train, X_valid=X_test, y_valid=y_test, threshold=THRESHOLD, verbose=False\n",
    "    )\n",
    "    # Salvando as variáveis preditoras:\n",
    "    features[v] = p['cat_variables']+p['num_variables']\n",
    "    # Salvando as métricas dos dados de treino:\n",
    "    metrics = metrics.append(\n",
    "        pd.DataFrame(\n",
    "            data=[{'Version':v, 'Model':model_label,'Data set':'train','AUC':train_mtcs['auc'],'Accuracy':train_mtcs['accuracy'],\n",
    "                   'Precision':train_mtcs['precision'],'Recall':train_mtcs['recall'],'F1_score':train_mtcs['f1_score']}]\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    # Salvando as métricas dos dados de teste:\n",
    "    metrics = metrics.append(\n",
    "        pd.DataFrame(\n",
    "            data=[{'Version':v,'Model':model_label,'Data set':'test','AUC':test_mtcs['auc'],'Accuracy':test_mtcs['accuracy'],\n",
    "                   'Precision':test_mtcs['precision'],'Recall':test_mtcs['recall'],'F1_score':test_mtcs['f1_score']}]\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# Fim do treinamento e avaliação:\n",
    "ept.end(msg=\"Tempo gasto:\")\n",
    "print(\"\\nWe trained and evaluated {} predictive models!\".format(len(models_version)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise das métricas nos dados de `teste`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v08</td>\n",
       "      <td>DTC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v07</td>\n",
       "      <td>DTC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v14</td>\n",
       "      <td>DTC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v16</td>\n",
       "      <td>DTC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Version Model Data set     AUC  Accuracy  Precision  Recall  F1_score\n",
       "0     v08   DTC     test  0.9000    0.8387     1.0000     0.8    0.8889\n",
       "1     v07   DTC     test  0.8167    0.8065     0.9524     0.8    0.8696\n",
       "2     v14   DTC     test  0.8167    0.8065     0.9524     0.8    0.8696\n",
       "3     v16   DTC     test  0.8167    0.8065     0.9524     0.8    0.8696"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os modelos com \"AUC >= 90%\":\n",
    "metrics.query(\"`Data set`=='test' and AUC>=0.8\").sort_values(by='AUC', ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v08</td>\n",
       "      <td>DTC</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v08</td>\n",
       "      <td>DTC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Version Model Data set  AUC  Accuracy  Precision  Recall  F1_score\n",
       "0     v08   DTC    train  1.0    1.0000        1.0     1.0    1.0000\n",
       "1     v08   DTC     test  0.9    0.8387        1.0     0.8    0.8889"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando as métricas de treino e teste da versão \"v08\":\n",
    "metrics.query(\"Version=='v08'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise:** a versão **`v08`** do modelo foi a versão que obteve o melhor desempenho em **todas** as métricas. Entretanto, podemos observar que nos dados de treino ele obteve uma performance **perfeita** conseguindo um desempenho de **100%** em todas as métricas. Ou seja, ocorreu um ajuste excessivo (**overfitting**) nos dados de treino (o modelo aprendeu demais o relacionamento dos dados).\n",
    "\n",
    "Agora, vamos trabalhar, nesta versão, com a **seleção de variáveis** para tentarmos construir um modelo **menos complexo**.\n",
    "\n",
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='modelos-selecao-variaveis'></a>\n",
    "## <font color='blue'>4- Trabalhando com `seleção de variáveis` nos melhores modelos preditivos</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um dicionário dos modelos que serão criados com os parâmetros de cada versão:\n",
    "models_version = {\n",
    "    'v17':{'train_set':'v1','cat_variables':cat_variables, 'num_variables':num_variables,'scaler':RobustScaler(),'balance':True,'random_state':SEED}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a avaliando cada `versão` do modelo preditivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento e avaliação com seleção de variáveis...\n",
      "\n",
      "Selected features: 1\n",
      "['Albumin']\n",
      "\n",
      "Tempo gasto: 1.09 seconds.\n",
      "\n",
      "We trained and evaluated 1 predictive models!\n"
     ]
    }
   ],
   "source": [
    "# Inicia o treinamento e avaliação de cada modelo:\n",
    "ept.start(msg=\"Iniciando o treinamento e avaliação com seleção de variáveis...\")\n",
    "# Loop para treinar e avaliar cada versão do modelo:\n",
    "for v, p in models_version.items():\n",
    "    # Preparando os dados de \"treino\" (X_train e y_train) e \"teste\" (X_test e y_test):\n",
    "    X_train, y_train, X_test, y_test, scaler[v] = mllib.prepare_train_test_data(\n",
    "    train_set=train_set[p['train_set']], test_set=test_set, target=target_variable, cat_features=p['cat_variables'],\n",
    "    num_features=p['num_variables'], scaler=p['scaler'], balance=p['balance'], random_state=p['random_state'], verbose=False\n",
    "    )\n",
    "    # Treinando e avaliando a versão do modelo preditivo:\n",
    "    models[v], train_mtcs, test_mtcs = mllib.train_validate_binary_clf_model(\n",
    "        classifier=RFECV(estimator=clf, step=1, cv=NUM_FOLDS, scoring='roc_auc', n_jobs=-1),\n",
    "        X_train=X_train, y_train=y_train, X_valid=X_test, y_valid=y_test, threshold=THRESHOLD, verbose=False\n",
    "    )\n",
    "    \n",
    "    # Visualizando as features selecionadas:\n",
    "    print(\"\\nSelected features: {}\".format(models[v].n_features_))\n",
    "    print(list(models[v].get_feature_names_out(input_features=p['cat_variables']+p['num_variables'])))\n",
    "    print() # pula 1 linha.\n",
    "    \n",
    "    # Salvando as variáveis preditoras:\n",
    "    features[v] = list(models[v].get_feature_names_out(input_features=p['cat_variables']+p['num_variables']))\n",
    "    # Salvando as métricas dos dados de treino:\n",
    "    metrics = metrics.append(\n",
    "        pd.DataFrame(\n",
    "            data=[{'Version':v, 'Model':model_label,'Data set':'train','AUC':train_mtcs['auc'],'Accuracy':train_mtcs['accuracy'],\n",
    "                   'Precision':train_mtcs['precision'],'Recall':train_mtcs['recall'],'F1_score':train_mtcs['f1_score']}]\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    # Salvando as métricas dos dados de teste:\n",
    "    metrics = metrics.append(\n",
    "        pd.DataFrame(\n",
    "            data=[{'Version':v,'Model':model_label,'Data set':'test','AUC':test_mtcs['auc'],'Accuracy':test_mtcs['accuracy'],\n",
    "                   'Precision':test_mtcs['precision'],'Recall':test_mtcs['recall'],'F1_score':test_mtcs['f1_score']}]\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# Fim do treinamento e avaliação:\n",
    "ept.end(msg=\"Tempo gasto:\")\n",
    "print(\"\\nWe trained and evaluated {} predictive models!\".format(len(models_version)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise das métricas nos dados de `teste`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v08</td>\n",
       "      <td>DTC</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v08</td>\n",
       "      <td>DTC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v17</td>\n",
       "      <td>DTC</td>\n",
       "      <td>train</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.9278</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.9307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v17</td>\n",
       "      <td>DTC</td>\n",
       "      <td>test</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Version Model Data set     AUC  Accuracy  Precision  Recall  F1_score\n",
       "0     v08   DTC    train  1.0000    1.0000     1.0000  1.0000    1.0000\n",
       "1     v08   DTC     test  0.9000    0.8387     1.0000  0.8000    0.8889\n",
       "2     v17   DTC    train  0.9863    0.9278     0.8952  0.9691    0.9307\n",
       "3     v17   DTC     test  0.6667    0.8065     0.9130  0.8400    0.8750"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparando as duas versões dos modelos:\n",
    "metrics.query(\"Version=='v08' or Version=='v17'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise:** a versão **`v17`** obteve um desempenho **ruim** em relação a versão **`v08`**, ou seja, a seleção de variáveis, neste caso, não obteve um resultado satisfatório.\n",
    "\n",
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='modelos-conclusao'></a>\n",
    "## <font color='blue'>5- Concluir e salvar o `melhor modelo preditivo` construído com o *Decision Tree Classifier*</font>\n",
    "\n",
    "Portanto, o modelo preditivo construido na versão **`v08`** obteve o melhor desempenho na métrica **`AUC`** e também nas outras métricas e por isso, ele foi escolhido como o **melhor modelo preditivo construído com o `DTC`**.\n",
    "\n",
    "Este modelo foi contruido com as seguintes premissas:\n",
    "* utilizamos a `versão 1` dos dados de treino;\n",
    "\n",
    "* utilizamos **todas** as variáveis preditoras;\n",
    "\n",
    "* aplicamos a **padronização de escala**, utilizando a classe `RobustScaler` nas variáveis numéricas;\n",
    "\n",
    "* **SIM**, fizemos o **balanceamento** do *dataset* de treino, ou seja, criamos registros sintéticos da classe minoritária (`target = 0`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando *todas* as informações do melhor modelo de classificação com `Decision Tree Classifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor versão do modelo preditivo:\n",
    "best_version = 'v08'\n",
    "# Cria dataframes para salvar as melhores métricas de treino e teste:\n",
    "best_train_mtcs = metrics.query(\"Version==@best_version and `Data set`=='train'\").reset_index(drop=True)\n",
    "best_test_mtcs = metrics.query(\"Version==@best_version and `Data set`=='test'\").reset_index(drop=True)\n",
    "# Remove a coluna 'Version':\n",
    "best_train_mtcs.drop(columns='Version', inplace=True)\n",
    "best_test_mtcs.drop(columns='Version', inplace=True)\n",
    "# Salva as melhores métricas criadas com este algoritmo:\n",
    "models_best_metrics = models_best_metrics.append(best_train_mtcs, ignore_index=True)\n",
    "models_best_metrics = models_best_metrics.append(best_test_mtcs, ignore_index=True)\n",
    "# Salva as variáveis preditoras, scaler e modelo da melhor versão:\n",
    "best_model = {\n",
    "    'variables': features[best_version],\n",
    "    'scaler': scaler[best_version],\n",
    "    'model': models[best_version]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as métricas dos melhores modelos preditivos:\n",
    "dslib.pickle_object_save (\n",
    "    path=ML_PATH, file=\"models_best_metrics.pkl\", object_name=models_best_metrics, msg=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as informações do melhor modelo preditivo criado com o \"DTC\":\n",
    "dslib.pickle_object_save (\n",
    "    path=ML_PATH, file=\"dtc_best_model.pkl\", object_name=best_model, msg=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>FIM</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
