{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# `Project:` Prevendo a <font color='blue'>morte</font> ou <font color='blue'>vida</font> de pacientes com hepatite\n",
    "\n",
    "## `Date:` fevereiro, 2022\n",
    "\n",
    "## `Data Scientist:` Walter Trevisan\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='notebook-header'></a>\n",
    "## `Modelagem Preditiva` (*`Machine Learning`*)\n",
    "\n",
    "Nesta fase, vamos iniciar a etapa de **modelagem preditiva**, treinando e analisando alguns algoritmos de classificação. Para fazermos o treinamento dos modelos utilizaremos os *datasets* de treino e para avaliarmos a performance dos modelos utilizaremos os *datasets* de teste que foram criados e preparados na etapa anterior (`Data Munging`).\n",
    "\n",
    "### Conteúdo\n",
    "1. [Setup Inicial](#initial-setup)\n",
    "\n",
    "2. [Definir os **algoritmos de classificação**](#estimators-define)\n",
    "\n",
    "3. [Definir e explicar as **métricas de classificação** que serão utilizadas](#metrics-define)\n",
    "\n",
    "4. [Criar e salvar *objeto* onde serão armazenadas as métricas dos **melhores** modelos preditivos](#metrics-save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='initial-setup'></a>\n",
    "## <font color='blue'>1- Setup Inicial:</font>\n",
    "\n",
    "Primeiro, vamos carregar os **pacotes e funções** que serão utilizadas neste **notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "# As novas versões do Pandas e Matplotlib trazem diversas mensagens de aviso ao desenvolvedor.\n",
    "# Então, vamos desativar essas mensagens.\n",
    "import sys # O pacote \"sys\" permite manipulações com o sistema operacional:\n",
    "import os  # Operation System (Packages and Functions)\n",
    "import warnings\n",
    "\n",
    "# Importa função para verificarmos a versão da linguagem python:\n",
    "from platform import python_version\n",
    "\n",
    "# Importando os pacote Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "# Definindo o diretório raiz (Root) onde serão armazenados todas as informações\n",
    "# (Imagens, Gráficos, Objetos, Dados, Modelos de ML, etc...) do projeto.\n",
    "# Diretório Raiz (Root) do Projeto:\n",
    "ROOT_DIR = \".\"\n",
    "\n",
    "# Path: onde ficarão armazenados os \"Objetos\" (Estrututras de Dados) relacionados ao Projeto:\n",
    "OBJ_PATH = os.path.join(ROOT_DIR, \"objects\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(OBJ_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde ficarão armazenados os \"datasets\" (arquivos \"csv\") e os \"objetos\" (Data Frames) do Projeto:\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde serão armazenadas as \"Imagens\" (Figuras e Gráficos) do Projeto:\n",
    "GRAPHICS_PATH = os.path.join(ROOT_DIR, \"images\", \"graphics\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(GRAPHICS_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde ficarão armazenados os \"Modelos Preditivos\" (Machine Learning) relacionados ao Projeto:\n",
    "ML_PATH = os.path.join(ROOT_DIR, \"models\")\n",
    "# Criando o diretório, se ele não existir:\n",
    "os.makedirs(ML_PATH, exist_ok=True)\n",
    "\n",
    "# Path: onde estão armazenadas as classes e funções que serão utilizadas neste notebook:\n",
    "LIB_PATH = os.path.join(ROOT_DIR, \"library\")\n",
    "\n",
    "# Adicionando o diretório \"./library\" ao 'path' do Sistema, para podermos importar classes e funções que serão\n",
    "# utilizadas neste notebook:\n",
    "sys.path.append(LIB_PATH)\n",
    "\n",
    "# Importando para este notebook, as classes e funções definidas no módulo \"data_science_library.py\":\n",
    "import data_science_library as dslib\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versões dos pacotes usados neste jupyter notebook:\n",
      "Python      : 3.8.12\n",
      "Pandas      : 1.3.5\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook:\n",
    "print(\"Versões dos pacotes usados neste jupyter notebook:\")\n",
    "print(\"Python      : {}\".format(python_version()))\n",
    "print(\"Pandas      : {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='estimators-define'></a>\n",
    "## <font color='blue'>2- Definir os algoritmos de classificação</font>\n",
    "\n",
    "Nesta fase serão utilizados os seguintes algoritmos de classificação:\n",
    "- **Logistic Regression**: modelos construídos no *notebook*: `5-Machine-Learning-LR.ipynb`;\n",
    "\n",
    "\n",
    "- **Decision Tree Classifier**: modelos construídos no *notebook*: `5-Machine-Learning-DTC.ipynb`;\n",
    "\n",
    "\n",
    "- **Support Vector Classification**: modelos construídos no *notebook*: `5-Machine-Learning-SVC.ipynb`;\n",
    "\n",
    "\n",
    "- **K Neighbors Classifier**: modelos construídos no *notebook*: `5-Machine-Learning-KNN.ipynb`;\n",
    "\n",
    "\n",
    "- **Naive Bayes**: modelos construídos no *notebook*: `5-Machine-Learning-NB.ipynb`;\n",
    "\n",
    "\n",
    "- **XGBoost Classifier**: modelos construídos no *notebook*: `5-Machine-Learning-XGBC.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='metrics-define'></a>\n",
    "## <font color='blue'>3- Definir e explicar as `métricas de classificação` que serão utilizadas</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas: `Accuracy`, `Precision`, `Recall`, `f1-score` e `ROC Curve (AUC)`\n",
    "\n",
    "### `Accuracy`:\n",
    "\n",
    "A **acurácia** do modelo mede a taxa de acertos das classes ***True Positive*** e ***True Negative***, sendo calculada pela fórmula abaixo:\n",
    "\n",
    "**`Accuracy = (TP + TN)/(TP + TN + FP + FN)`**, onde:\n",
    "\n",
    "1. **`TP`** é o número de ***verdadeiros positivos***;\n",
    "\n",
    "2. **`TN`** é o número de ***verdadeiros negativos***;\n",
    "\n",
    "3. **`FP`** é o número de ***falsos positivos***.\n",
    "\n",
    "4. **`FN`** é o número de ***falsos negativos***.\n",
    "\n",
    "Um classificador perfeito teria apenas *verdadeiros positivos* (**TP**) e *verdadeiros negativos* (**TN**), ou seja, sua **matriz de confusão** teria valores diferentes de zero somente na sua diagonal principal (superior esquerda para a inferior direita), ou seja, a sua acurácia (**`accuracy`**) seria de **100%**.\n",
    "\n",
    "### `Precision`:\n",
    "\n",
    "Uma outra métrica interessante a ser observada na ***matriz de confusão*** é a `acurácia das previsões positivas`; que é chamada de ***precisão (precision)*** do classificador e é calculada pela fórmula abaixo:\n",
    "\n",
    "**`Precision = TP/(TP + FP)`**, onde:\n",
    "\n",
    "1. **`TP`** é o número de ***verdadeiros positivos***;\n",
    "\n",
    "2. **`FP`** é o número de ***falsos positivos***.\n",
    "\n",
    "### `Recall`:\n",
    "\n",
    "Entretanto, a precisão é utilizada em conjunto com outra métrica chamada ***revocação (recall)***, também conhecida como ***sensibilidade*** ou ***taxa de verdadeiros positivos (TPR)***: esta é a taxa de `instâncias positivas que são corretamente detectadas` pelo classificador, sendo calculada pela fórmula abaixo:\n",
    "\n",
    "**`Recall = TP/(TP + FN)`**, onde:\n",
    "\n",
    "1. **`TP`** é o número de ***verdadeiros positivos***;\n",
    "\n",
    "2. **`FN`** é o número de ***falsos negativos***.\n",
    "\n",
    "### `f1-score`:\n",
    "\n",
    "Muitas vezes, é conveniente combinarmos **precisão** e **revocação** em uma única métrica chamada ***pontuação F1 (f1 score)***, principalmente se precisarmos comparar dois ou mais classificadores.\n",
    "\n",
    "A ***pontuação F1*** é a ***média harmônica*** da **precisão** e **revocação**, sendo calculada pela fórmula abaixo:\n",
    "\n",
    "**`F1 = TP/(TP + (FN + FP)/2)`**, onde:\n",
    "\n",
    "1. **`TP`** é o número de ***verdadeiros positivos***;\n",
    "\n",
    "2. **`FN`** é o número de ***falsos negativos***;\n",
    "\n",
    "3. **`FP`** é o número de ***falsos positivos***.\n",
    "\n",
    "Enquanto a média regular trata igualmente todos os valores, a média harmônica dá muito mais peso aos valores mais baixos, ou seja, o classificador só obterá uma ***pontuação F1*** alta, se a **revocação** e a **precisão** forem altas.\n",
    "\n",
    "### `ROC Curve (AUC)`\n",
    "\n",
    "A curva **ROC** (*características operacionais do receptor*) é outra ferramenta comum utilizada com classificadores binários. É muito semelhante à curva de **`precision/recall`**, mas, em vez de plotar a **precision versus recall**, a curva **ROC** plota a *taxa de verdadeiros positivos* (***TPR = True Positive Rate***), que é um outro nome dado para ***recall***, versus a *taxa de falsos positivos* (***FPR = False Positive Rate***). O ***FPR*** é a razão de instâncias negativas incorretamente classificadas como positivas. É igual a 1 menos *taxa de verdadeiros negativos* (***TNR = True Negative Rate***), que é a razão de instâncias negativas que são corretamente classificadas como negativas. A ***TNR*** também é chamada de ***especificidade***.\n",
    "\n",
    "Portanto, a ***Curva ROC*** plota a ***`sensibilidade (recall)` versus `1 - especificidade`***.\n",
    "\n",
    "Equações:\n",
    "\n",
    "1. **`TPR = TP/(TP + FN)`** --> ***True Positive Rate***, ou também ***`recall`*** ou também ***`sensibilidade`***\n",
    "\n",
    "2. **`FPR = FP/(FP + TN)`** --> ***False Positive Rate***\n",
    "\n",
    "3. **`TNR = TN/(TN + FP)`** --> ***True Negative Rate***, ou também ***especificidade***\n",
    "\n",
    "4. **`FPR = 1 - TNR`** ou também **`FPR = 1 - especificidade`**\n",
    "\n",
    "Uma forma de compararmos dois ou mais classificadores é medirmos a **área abaixo da curva** (***`AUC = Area Under Curve`***). Um classificador perfeito terá um ***`ROC AUC = 1`***, enquanto que um classificador puramente aleatório terá um ***`ROC AUC = 0.5`***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name='metrics-save'></a>\n",
    "## <font color='blue'>4- Criar e salvar *objeto* onde serão armazenadas as métricas dos `melhores` modelos preditivos</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data set</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Data set, AUC, Accuracy, Precision, Recall, F1_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando o dataframe para armazenar as métricas da melhor versão de cada algoritmo:\n",
    "models_best_metrics = pd.DataFrame(columns=['Model', 'Data set', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "models_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as métricas dos melhores modelos preditivos:\n",
    "dslib.pickle_object_save (\n",
    "    path=ML_PATH, file=\"models_best_metrics.pkl\", object_name=models_best_metrics, msg=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retornar ao ínicio deste **notebook** clique **[aqui](#notebook-header)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>FIM</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
